# Flexibilidad, grafos y arquitecturas neuronales: El caso de Qwen 2.5

## 游깷 Cambiar Idioma

-  [游섫릖 English](https://economiayetica.blogspot.com/2025/02/flexibilidad-grafos-y-arquitecturas_2.html))



## 1. Modelos densos versus MoE

El objetivo de esta nota es analizar, usando teor칤a de los grafos, la diferencia entre la arquitectura de un modelo denso y un MoE (Mixture of Experts), tomando como ejemplo el reciente modelo desarrollado por Alibaba: **Qwen 2.5**.

## 2. 쯈u칠 son los modelos densos en el contexto de redes neuronales y modelos de lenguaje?

Un modelo denso (**Dense Model**) es un tipo de modelo de red neuronal en el que todos los par치metros se activan y utilizan en cada paso de inferencia o entrenamiento. Esto significa que cada una de las neuronas o unidades de la arquitectura contribuye significativamente al procesamiento de los datos en cada iteraci칩n.

Las siguientes son las caracter칤sticas clave de los modelos densos:

- **Todos los par치metros se utilizan simult치neamente:** En cada forward pass (paso de inferencia) o backward pass (paso de entrenamiento), todas las capas y par치metros participan. Esta caracter칤stica los diferencia de los modelos MoE, en los cuales solo se activa un subconjunto de expertos en cada inferencia.
- **Uso de memoria y c칩mputo constante:** Al estar todas las conexiones activas todo el tiempo, el consumo de memoria y c칩mputo es predecible y fijo, dependiendo del n칰mero total de par치metros.
- **Generalmente m치s f치ciles de implementar:** Su estructura uniforme y simple facilita el entrenamiento, sin requerir el enrutamiento de expertos que demandan los modelos MoE.

Con esta definici칩n, pasamos a estudiar el reciente modelo de la empresa Alibaba.

## 3. 쯈u칠 es Qwen 2.5?

Recientemente, Alibaba lanz칩 **Qwen 2.5**, el cual enriquece el ecosistema chino de Inteligencia Artificial y, debido a la creciente influencia de los sistemas de IA, su impacto se extiende m치s all치 de China. Qwen 2.5 es una serie de modelos de lenguaje a gran escala (LLMs) dise침ados para ofrecer una mejor comprensi칩n del lenguaje, generaci칩n de texto, razonamiento, matem치ticas y programaci칩n. Forma parte de la evoluci칩n de la familia Qwen, destac치ndose por su escalabilidad y eficiencia en comparaci칩n con versiones anteriores.

El modelo est치 disponible en dos formatos principales:

- **Modelos de c칩digo abierto ("Open-Weight")**: Accesibles en Hugging Face y otros repositorios.
- **Modelos propietarios (API en la nube)**: Optimados para una inferencia r치pida mediante t칠cnicas MoE.

Para el prop칩sito de esta nota se destacan dos implementaciones de Qwen 2.5, cada una con una arquitectura diferente:

**Comparativa:**

| Caracter칤stica             | Qwen2.5 Open-Weight (Modelo Denso)                | Qwen2.5-Turbo / Plus (MoE)                                           |
|----------------------------|---------------------------------------------------|----------------------------------------------------------------------|
| **Arquitectura**           | Dense Transformer                                 | Mixture of Experts (MoE)                                             |
| **Par치metros Activos**     | Se usan todos los par치metros en cada inferencia   | Solo se activa una fracci칩n de par치metros por consulta               |
| **Uso de C칩mputo**         | Alto, ya que todas las capas se activan siempre   | M치s eficiente, usando solo los expertos m치s relevantes               |
| **Escalabilidad**          | Limitada, requiere m치s GPUs para crecer           | Mayor, puede expandirse sin aumentar el c칩mputo proporcionalmente      |
| **Eficiencia en Inferencia** | M치s costosa y lenta                             | M치s r치pida y optimizada para producci칩n                              |
| **Disponibilidad**         | Open-weight (c칩digo abierto)                      | Disponible v칤a API en Alibaba Cloud                                  |

*Fuente: Elaboraci칩n propia*

Por ejemplo, **Qwen2.5 Open-Weight** es un modelo denso; todas sus capas y conexiones se activan en cada inferencia, lo que lo hace ideal para investigaci칩n en hardware de alto rendimiento, aunque con un costo computacional elevado. En cambio, **Qwen2.5-Turbo** y **Qwen2.5-Plus**, al ser modelos MoE, activan solo algunas partes seg칰n la entrada, reduciendo el consumo de memoria y acelerando la inferencia, lo que resulta m치s eficiente para aplicaciones en la nube.

## 4. Teor칤a de los grafos y arquitectura computacional

Desde el punto de vista de la teor칤a de grafos, un modelo denso puede interpretarse como un **grafo denso**, en el que todos los nodos (neuronas) est치n altamente conectados. Un grafo denso es aquel en el que el n칰mero de aristas (conexiones entre nodos) se acerca al m치ximo posible. Para un grafo dirigido con `N` nodos, el n칰mero m치ximo de aristas es `N(N-1)` (cada nodo puede conectarse con todos los dem치s).

Formalmente, la densidad de un grafo dirigido `G = (V, E)` se define como:

D(G) = |E| / (|V|(|V| - 1))

markdown
Copiar

Donde:
- `|V|` es el n칰mero de nodos (neuronas o capas de la red)
- `|E|` es el n칰mero de conexiones (pesos sin치pticos).

Si la densidad se acerca a 1, el grafo se considera denso; si se acerca a 0, es disperso (*sparse*).

En Deep Learning, un modelo denso se asemeja a un grafo casi completamente conectado, en el que:
- Las capas forman los nodos.
- Las conexiones sin치pticas representan las aristas.
- Cada nodo de una capa se conecta con todos los nodos de la siguiente (como en una fully connected layer).

## Conclusi칩n

El uso de modelos densos y MoE se refleja en la eficiencia del modelo y puede representarse mediante grafos. Los modelos densos (**Qwen2.5 Open-Weight**) tienen una densidad de grafo cercana a 1, utilizando todas las conexiones posibles, lo que implica un mayor uso de memoria y c칩mputo pero ofrece mayor consistencia en las respuestas. En contraste, los modelos MoE (**Qwen2.5-Turbo** y **Qwen2.5-Plus**) tienen una densidad mucho menor, activando solo una fracci칩n de expertos por inferencia, lo que permite escalabilidad sin un incremento proporcional en el costo de hardware.

![Grafos Completos](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjQtx6hUt9Vu_a-kVpLrj40BR_Hyhxc8zscng-88kB9vXLqF9xlcFLiivXR5uFeahe6tPssbksDsxHsKfDz_kKxBM_TPBpIwyOjlA7WPLwtJJcSPEsInVcFUzbToNjapspjPC0LDqf2YELbcAgzRiWWPAFoeWzx439Ypt5rYF2VOL5Ussn3Mr7b9CrOQBU/s320/grafos%20completos.gif)

Video generado por Qwen 2.5 representando un grafo denso y un grafo disperso.

[Reference: Qwen 2.5 Technical Report](https://arxiv.org/abs/2412.15115)
